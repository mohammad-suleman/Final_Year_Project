{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations xml to txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved class names to: /mnt/f/final2/China_MotorBike/China_MotorBike/train/labels/class_names.txt\n",
      "Conversion completed. YOLO annotations saved to '/mnt/f/final2/China_MotorBike/China_MotorBike/train/labels'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def voc_to_yolo_and_classes(xml_folder, output_folder):\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Set to store unique class names\n",
    "    classes = set()\n",
    "\n",
    "    # Collect all class names first\n",
    "    for xml_file in os.listdir(xml_folder):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            xml_path = os.path.join(xml_folder, xml_file)\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            for obj in root.findall('object'):\n",
    "                class_name = obj.find('name').text\n",
    "                classes.add(class_name)\n",
    "\n",
    "    # Sort classes and create class-to-ID mapping\n",
    "    sorted_classes = sorted(classes)\n",
    "    class_to_id = {class_name: i for i, class_name in enumerate(sorted_classes)}\n",
    "\n",
    "    # Save class names to file\n",
    "    classes_file = os.path.join(output_folder, \"class_names.txt\")\n",
    "    with open(classes_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(sorted_classes))\n",
    "\n",
    "    print(f\"Saved class names to: {classes_file}\")\n",
    "\n",
    "    # Process each XML file again to generate YOLO labels\n",
    "    for xml_file in os.listdir(xml_folder):\n",
    "        if not xml_file.endswith('.xml'):\n",
    "            continue\n",
    "\n",
    "        xml_path = os.path.join(xml_folder, xml_file)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Get image dimensions\n",
    "        size = root.find('size')\n",
    "        img_width = int(size.find('width').text)\n",
    "        img_height = int(size.find('height').text)\n",
    "\n",
    "        # Prepare YOLO annotations\n",
    "        yolo_annotations = []\n",
    "        for obj in root.findall('object'):\n",
    "            class_name = obj.find('name').text\n",
    "            class_id = class_to_id[class_name]  # âœ… Get correct ID\n",
    "\n",
    "            bbox = obj.find('bndbox')\n",
    "            xmin = float(bbox.find('xmin').text)\n",
    "            ymin = float(bbox.find('ymin').text)\n",
    "            xmax = float(bbox.find('xmax').text)\n",
    "            ymax = float(bbox.find('ymax').text)\n",
    "\n",
    "            # Convert to YOLO format\n",
    "            center_x = ((xmin + xmax) / 2) / img_width\n",
    "            center_y = ((ymin + ymax) / 2) / img_height\n",
    "            box_width = (xmax - xmin) / img_width\n",
    "            box_height = (ymax - ymin) / img_height\n",
    "\n",
    "            yolo_annotations.append(f\"{class_id} {center_x:.6f} {center_y:.6f} {box_width:.6f} {box_height:.6f}\")\n",
    "\n",
    "        # Save YOLO annotation to .txt file\n",
    "        yolo_file = os.path.join(output_folder, xml_file.replace('.xml', '.txt'))\n",
    "        with open(yolo_file, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "    print(f\"Conversion completed. YOLO annotations saved to '{output_folder}'.\")\n",
    "\n",
    "# Example Usage\n",
    "xml_folder = \"/mnt/f/final2/China_MotorBike/China_MotorBike/train/annotations/xmls\"\n",
    "output_folder = \"/mnt/f/final2/China_MotorBike/China_MotorBike/train/labels\"  \n",
    "\n",
    "voc_to_yolo_and_classes(xml_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated annotations in class_names.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to your YOLO annotation files\n",
    "annotation_folder = \"/mnt/f/final2/China_MotorBike/China_MotorBike/train/labels\"\n",
    "\n",
    "# Updated class mapping\n",
    "class_mapping = {\n",
    "    \"D00\": \"0\",\n",
    "    \"D01\": \"5\",\n",
    "    \"D0w0\": \"6\",\n",
    "    \"D10\": \"1\",\n",
    "    \"D11\": \"4\",\n",
    "    \"D20\": \"2\",\n",
    "    \"D40\": \"3\",\n",
    "    \"D43\": \"7\",\n",
    "    \"D44\": \"8\",\n",
    "    \"D50\": \"9\"\n",
    "}\n",
    "\n",
    "# Function to update YOLO annotations\n",
    "def update_class_names(annotation_folder, class_mapping):\n",
    "   \n",
    "    if not os.path.exists(annotation_folder):\n",
    "        print(f\"Annotation folder {annotation_folder} does not exist.\")\n",
    "        return\n",
    "\n",
    "    for file_name in os.listdir(annotation_folder):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(annotation_folder, file_name)\n",
    "\n",
    "            with open(file_path, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            updated_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if parts:  # Ensure line is not empty\n",
    "                    old_class_name = parts[0]\n",
    "                    if old_class_name in class_mapping:\n",
    "                        parts[0] = class_mapping[old_class_name]  # Update class ID\n",
    "                        updated_lines.append(\" \".join(parts))\n",
    "\n",
    "            # Only update the file if changes were made\n",
    "            if updated_lines:\n",
    "                with open(file_path, \"w\") as file:\n",
    "                    file.write(\"\\n\".join(updated_lines))\n",
    "\n",
    "                print(f\"Updated annotations in {file_name}\")\n",
    "\n",
    "update_class_names(annotation_folder, class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: 277 annotations\n",
      "Class 2: 1476 annotations\n",
      "Class 0: 9429 annotations\n",
      "Class 3: 371 annotations\n",
      "Class 1: 4392 annotations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "ANNOTATIONS_DIR = \"/mnt/f/final2/China_MotorBike/China_MotorBike/train/labels\" \n",
    "\n",
    "\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "for file in os.listdir(ANNOTATIONS_DIR):\n",
    "    if file.endswith(\".txt\"):  \n",
    "        with open(os.path.join(ANNOTATIONS_DIR, file), \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                class_id = line.split()[0]  \n",
    "                class_counts[class_id] += 1\n",
    "\n",
    "# Print class distribution\n",
    "for class_id, count in class_counts.items():\n",
    "    print(f\"Class {class_id}: {count} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Spliting (Train-Val-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed!\n",
      " Train: 7759 images\n",
      " Validation: 2217 images\n",
      " Test: 1109 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define source directories\n",
    "SOURCE_IMAGE_DIR = \"/mnt/f/final2/China_MotorBike/China_MotorBike/train/images\"  \n",
    "SOURCE_LABEL_DIR = \"/mnt/f/final2/China_MotorBike/China_MotorBike/train/labels\"  \n",
    "\n",
    "# Define base output directory\n",
    "OUTPUT_DIR = \"/mnt/f/final2/DATASET\"\n",
    "\n",
    "# Define train, val, and test subdirectories dynamically\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "for split in SPLITS:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, split, \"labels\"), exist_ok=True)\n",
    "\n",
    "# Get all image files (assuming .jpg and .png images)\n",
    "image_files = [f for f in os.listdir(SOURCE_IMAGE_DIR) if f.endswith((\".jpg\", \".png\"))]\n",
    "random.shuffle(image_files)  # Shuffle to ensure random distribution\n",
    "\n",
    "# Calculate split indices\n",
    "total_images = len(image_files)\n",
    "train_split = int(0.7 * total_images)\n",
    "val_split = int(0.2 * total_images)\n",
    "\n",
    "train_files = image_files[:train_split]\n",
    "val_files = image_files[train_split:train_split + val_split]\n",
    "test_files = image_files[train_split + val_split:]\n",
    "\n",
    "# Function to move images and corresponding labels\n",
    "def move_files(files, src_img_dir, src_label_dir, dest_img_dir, dest_label_dir):\n",
    "    for file in files:\n",
    "        # Move image\n",
    "        shutil.move(os.path.join(src_img_dir, file), os.path.join(dest_img_dir, file))\n",
    "\n",
    "        # Move corresponding label file (if it exists)\n",
    "        label_file = file.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "        label_path = os.path.join(src_label_dir, label_file)\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.move(label_path, os.path.join(dest_label_dir, label_file))\n",
    "\n",
    "# Move files to respective folders\n",
    "move_files(train_files, SOURCE_IMAGE_DIR, SOURCE_LABEL_DIR, os.path.join(OUTPUT_DIR, \"train/images\"), os.path.join(OUTPUT_DIR, \"train/labels\"))\n",
    "move_files(val_files, SOURCE_IMAGE_DIR, SOURCE_LABEL_DIR, os.path.join(OUTPUT_DIR, \"val/images\"), os.path.join(OUTPUT_DIR, \"val/labels\"))\n",
    "move_files(test_files, SOURCE_IMAGE_DIR, SOURCE_LABEL_DIR, os.path.join(OUTPUT_DIR, \"test/images\"), os.path.join(OUTPUT_DIR, \"test/labels\"))\n",
    "\n",
    "# Summary of the split\n",
    "print(\"Dataset split completed!\")\n",
    "print(f\" Train: {len(train_files)} images\")\n",
    "print(f\" Validation: {len(val_files)} images\")\n",
    "print(f\" Test: {len(test_files)} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Irrelevant Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning completed. Run the label check script again to verify!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the validation labels\n",
    "VAL_LABELS_DIR = \"/mnt/f/final2/DATASET/train/labels\"\n",
    "\n",
    "# Define the classes to remove\n",
    "UNWANTED_CLASSES = {\"7\", \"8\", \"9\", \"Repair\"}\n",
    "\n",
    "def clean_labels(label_dir):\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(label_dir, label_file)\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Keep only lines that don't have unwanted class labels\n",
    "            filtered_lines = [line for line in lines if line.split()[0] not in UNWANTED_CLASSES]\n",
    "\n",
    "            # Overwrite the file with cleaned data\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.writelines(filtered_lines)\n",
    "\n",
    "            # Print info if file was modified\n",
    "            if len(lines) != len(filtered_lines):\n",
    "                print(f\"Cleaned {label_file}: Removed {len(lines) - len(filtered_lines)} instances\")\n",
    "\n",
    "# Run the cleaning function\n",
    "clean_labels(VAL_LABELS_DIR)\n",
    "\n",
    "print(\"\\nCleaning completed. Run the label check script again to verify!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label merging and cleaning completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def merge_and_clean_labels(labels_folder):\n",
    "    for label_file in os.listdir(labels_folder):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(labels_folder, label_file)\n",
    "\n",
    "            # Read original labels\n",
    "            with open(file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    continue  # Skip empty lines\n",
    "\n",
    "                class_id = parts[0]\n",
    "\n",
    "                # Convert to integer\n",
    "                if class_id.endswith(\".0\"):\n",
    "                    class_id = class_id[:-2]  # Remove .0\n",
    "\n",
    "                # Remove class 4\n",
    "                if class_id == \"4\":\n",
    "                    continue  \n",
    "\n",
    "                # Reconstruct the YOLO annotation line\n",
    "                new_line = f\"{class_id} \" + \" \".join(parts[1:])\n",
    "                new_lines.append(new_line)\n",
    "\n",
    "            # Overwrite file with cleaned labels\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(new_lines))\n",
    "\n",
    "    print(\"Label merging and cleaning completed!\")\n",
    "\n",
    "# Example usage\n",
    "labels_folder = \"/mnt/f/final2/DATASET/train/labels\"  \n",
    "merge_and_clean_labels(labels_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Label Distribution in Train Set:\n",
      "Class 0: 8251 instances\n",
      "Class 1: 3884 instances\n",
      "Class 2: 2620 instances\n",
      "Class 3: 3114 instances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your validation labels directory\n",
    "VAL_LABELS_DIR = \"/mnt/f/final2/DATASET/train/labels\"\n",
    "\n",
    "def count_labels(label_dir):\n",
    "    class_counter = Counter()\n",
    "\n",
    "    if not os.path.exists(label_dir):\n",
    "        print(f\"Directory {label_dir} does not exist!\")\n",
    "        return\n",
    "\n",
    "    # Read each annotation file\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            with open(os.path.join(label_dir, label_file), \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        class_label = parts[0]  # First item is the class ID\n",
    "                        class_counter[class_label] += 1\n",
    "\n",
    "    return class_counter\n",
    "\n",
    "# Run the function on val set\n",
    "label_counts = count_labels(VAL_LABELS_DIR)\n",
    "\n",
    "# Print the label distribution\n",
    "if label_counts:\n",
    "    print(\"\\nClass Label Distribution in Train Set:\")\n",
    "    for class_label, count in sorted(label_counts.items()):\n",
    "        print(f\"Class {class_label}: {count} instances\")\n",
    "else:\n",
    "    print(\"No labels found in Train set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Cleaning completed. Run the label check script again to verify!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the validation labels\n",
    "VAL_LABELS_DIR = \"/mnt/f/final2/DATASET/test/labels\"\n",
    "\n",
    "# Define the classes to remove\n",
    "UNWANTED_CLASSES = {\"7\", \"8\", \"9\", \"Repair\"}\n",
    "\n",
    "def clean_labels(label_dir):\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(label_dir, label_file)\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Keep only lines that don't have unwanted class labels\n",
    "            filtered_lines = [line for line in lines if line.split()[0] not in UNWANTED_CLASSES]\n",
    "\n",
    "            # Overwrite the file with cleaned data\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.writelines(filtered_lines)\n",
    "\n",
    "            # Print info if file was modified\n",
    "            if len(lines) != len(filtered_lines):\n",
    "                print(f\"Cleaned {label_file}: Removed {len(lines) - len(filtered_lines)} instances\")\n",
    "\n",
    "# Run the cleaning function\n",
    "clean_labels(VAL_LABELS_DIR)\n",
    "\n",
    "print(\"\\nâœ… Cleaning completed. Run the label check script again to verify!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label merging and cleaning completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def merge_and_clean_labels(labels_folder):\n",
    "    for label_file in os.listdir(labels_folder):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(labels_folder, label_file)\n",
    "\n",
    "            # Read original labels\n",
    "            with open(file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    continue  # Skip empty lines\n",
    "\n",
    "                class_id = parts[0]\n",
    "\n",
    "                # Convert to integer\n",
    "                if class_id.endswith(\".0\"):\n",
    "                    class_id = class_id[:-2]  # Remove .0\n",
    "\n",
    "                # Remove class 4\n",
    "                if class_id == \"4\":\n",
    "                    continue  \n",
    "\n",
    "                # Reconstruct the YOLO annotation line\n",
    "                new_line = f\"{class_id} \" + \" \".join(parts[1:])\n",
    "                new_lines.append(new_line)\n",
    "\n",
    "            # Overwrite file with cleaned labels\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(new_lines))\n",
    "\n",
    "    print(\"Label merging and cleaning completed!\")\n",
    "\n",
    "# Example usage\n",
    "labels_folder = \"/mnt/f/final2/DATASET/test/labels\"  \n",
    "merge_and_clean_labels(labels_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Label Distribution in Test Set:\n",
      "Class 0: 1248 instances\n",
      "Class 1: 572 instances\n",
      "Class 2: 362 instances\n",
      "Class 3: 395 instances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your validation labels directory\n",
    "VAL_LABELS_DIR = \"/mnt/f/final2/DATASET/test/labels\"\n",
    "\n",
    "def count_labels(label_dir):\n",
    "    class_counter = Counter()\n",
    "\n",
    "    if not os.path.exists(label_dir):\n",
    "        print(f\"Directory {label_dir} does not exist!\")\n",
    "        return\n",
    "\n",
    "    # Read each annotation file\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            with open(os.path.join(label_dir, label_file), \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        class_label = parts[0]  # First item is the class ID\n",
    "                        class_counter[class_label] += 1\n",
    "\n",
    "    return class_counter\n",
    "\n",
    "# Run the function on val set\n",
    "label_counts = count_labels(VAL_LABELS_DIR)\n",
    "\n",
    "# Print the label distribution\n",
    "if label_counts:\n",
    "    print(\"\\nClass Label Distribution in Test Set:\")\n",
    "    for class_label, count in sorted(label_counts.items()):\n",
    "        print(f\"Class {class_label}: {count} instances\")\n",
    "else:\n",
    "    print(\"No labels found in test set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Val Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cleaning completed. Run the label check script again to verify!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the validation labels\n",
    "VAL_LABELS_DIR = \"/mnt/f/final2/DATASET/val/labels\"\n",
    "\n",
    "# Define the classes to remove\n",
    "UNWANTED_CLASSES = {\"7\", \"8\", \"9\", \"Repair\"}\n",
    "\n",
    "def clean_labels(label_dir):\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(label_dir, label_file)\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Keep only lines that don't have unwanted class labels\n",
    "            filtered_lines = [line for line in lines if line.split()[0] not in UNWANTED_CLASSES]\n",
    "\n",
    "            # Overwrite the file with cleaned data\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.writelines(filtered_lines)\n",
    "\n",
    "            # Print info if file was modified\n",
    "            if len(lines) != len(filtered_lines):\n",
    "                print(f\"Cleaned {label_file}: Removed {len(lines) - len(filtered_lines)} instances\")\n",
    "\n",
    "# Run the cleaning function\n",
    "clean_labels(VAL_LABELS_DIR)\n",
    "\n",
    "print(\"\\n Cleaning completed. Run the label check script again to verify!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label merging and cleaning completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def merge_and_clean_labels(labels_folder):\n",
    "    for label_file in os.listdir(labels_folder):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(labels_folder, label_file)\n",
    "\n",
    "            # Read original labels\n",
    "            with open(file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    continue  # Skip empty lines\n",
    "\n",
    "                class_id = parts[0]\n",
    "\n",
    "                # Convert to integer\n",
    "                if class_id.endswith(\".0\"):\n",
    "                    class_id = class_id[:-2]  # Remove .0\n",
    "\n",
    "                # Remove class 4\n",
    "                if class_id == \"4\":\n",
    "                    continue  \n",
    "\n",
    "                # Reconstruct the YOLO annotation line\n",
    "                new_line = f\"{class_id} \" + \" \".join(parts[1:])\n",
    "                new_lines.append(new_line)\n",
    "\n",
    "            # Overwrite file with cleaned labels\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(new_lines))\n",
    "\n",
    "    print(\"Label merging and cleaning completed!\")\n",
    "\n",
    "# Example usage\n",
    "labels_folder = \"/mnt/f/final2/DATASET/val/labels\"  \n",
    "merge_and_clean_labels(labels_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Label Distribution in Validation Set:\n",
      "Class 0: 2438 instances\n",
      "Class 1: 1227 instances\n",
      "Class 2: 748 instances\n",
      "Class 3: 906 instances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your validation labels directory\n",
    "VAL_LABELS_DIR = \"/mnt/f/final2/DATASET/val/labels\"\n",
    "\n",
    "def count_labels(label_dir):\n",
    "    class_counter = Counter()\n",
    "\n",
    "    if not os.path.exists(label_dir):\n",
    "        print(f\"Directory {label_dir} does not exist!\")\n",
    "        return\n",
    "\n",
    "    # Read each annotation file\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            with open(os.path.join(label_dir, label_file), \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        class_label = parts[0]  # First item is the class ID\n",
    "                        class_counter[class_label] += 1\n",
    "\n",
    "    return class_counter\n",
    "\n",
    "# Run the function on val set\n",
    "label_counts = count_labels(VAL_LABELS_DIR)\n",
    "\n",
    "# Print the label distribution\n",
    "if label_counts:\n",
    "    print(\"\\nClass Label Distribution in Validation Set:\")\n",
    "    for class_label, count in sorted(label_counts.items()):\n",
    "        print(f\"Class {class_label}: {count} instances\")\n",
    "else:\n",
    "    print(\"No labels found in validation set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loboFyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
